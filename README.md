# Generalized LM Studio MCP Server

A universal Model Context Protocol (MCP) server that automatically adapts to any LM Studio model's capabilities. Works with text-only models, vision models, and everything in between!

## üéØ Why This Tool Exists

**The Problem**: In Cursor AI IDE, even when your LM Studio model has image analysis capabilities, you can only use them by manually including images in the context using the `@` symbol. If you ask the AI to read an image file from a location, or if an image was auto-generated by your application, Cursor's default tools can't "see" the image - they only work with text files, not binary data.

**The Solution**: This MCP server bridges that gap by providing direct image analysis tools that work seamlessly with any vision-capable model in LM Studio. Now your AI can automatically analyze screenshots, read text from images, compare visuals, and more - all without manual file inclusion.

**Real Example**: Instead of manually dragging an auto-generated chart into Cursor with `@`, you can simply ask: *"Analyze the chart at ./output/sales_chart.png and explain the trends"* - and the AI will automatically see and analyze the image.

## üöÄ Quick Start

1. **Install dependencies**: `pip install -r requirements.txt`
2. **Start LM Studio** with any model loaded
3. **Test the server**: `python test_generalized_server.py`
4. **Configure your MCP client** using `cursor_mcp_config.json` (‚ö†Ô∏è **update the path!**)

## ‚ú® Features

### üåê Universal Compatibility
- **Any Model**: Works with text-only models (Phi-4, DeepSeek, etc.)
- **Vision Models**: Automatically detects and enables vision tools (Gemma-3-27B-IT, LLaVA, etc.)
- **Auto-Adaptation**: Tools appear/disappear based on model capabilities
- **No Restart**: Switch models in LM Studio - just refresh in Cursor settings

### üõ†Ô∏è Available Tools

**Always Available:**
- Health checks and model management
- Text completions and chat

**Vision Models Only:**
- Image analysis and description
- Screenshot analysis (UI elements, layout, accessibility)
- Text extraction from images (OCR-like)
- Image comparisons
- Batch image processing
- Conversational image chat

## üìö Documentation

- **[Quick Start Guide](QUICK_START.md)** - Get running in 3 steps
- **[Setup Instructions](SETUP_INSTRUCTIONS.md)** - Detailed setup and troubleshooting
- **[Technical Documentation](README_GENERALIZED.md)** - Full technical details

## üß™ Try the Demo

```bash
python demo_capability_adaptation.py
```

See how the server automatically detects your model's capabilities!

## üîß Configuration

**‚ö†Ô∏è IMPORTANT**: Cursor has its own environment, so direct Python calls may not work.

**Windows (Recommended)**: Use the batch file:
```json
{
  "mcpServers": {
    "lm-studio-mcp-generalized": {
      "command": "C:\\path\\to\\your\\custom-lm-studio-mcp-generalized-2\\start_generalized_mcp.bat"
    }
  }
}
```

**macOS/Linux**: Use the Python launcher:
```json
{
  "mcpServers": {
    "lm-studio-mcp-generalized": {
      "command": "python3",
      "args": ["/path/to/your/custom-lm-studio-mcp-generalized-2/launch_server.py"]
    }
  }
}
```

**Example paths:**
- **Windows**: `"C:\\Users\\YourName\\PROJECTS\\custom-lm-studio-mcp-generalized-2\\start_generalized_mcp.bat"`
- **macOS**: `"/Users/YourName/Projects/custom-lm-studio-mcp-generalized-2/launch_server.py"`
- **Linux**: `"/home/YourName/Projects/custom-lm-studio-mcp-generalized-2/launch_server.py"`

## üéØ Why This Server?

- **Solves Cursor's Image Limitation**: Enables automatic image analysis without manual `@` file inclusion
- **One Server, All Models**: No need for different servers for different models
- **Zero Configuration**: Automatically detects what your model can do
- **Seamless Integration**: Works directly with Cursor's AI without workflow interruption
- **Cross-Platform**: Works on Windows, macOS, and Linux
- **Future-Proof**: Works with new models as they're released
- **Clean & Simple**: No complex setup once paths are configured

## üìã Requirements

- Python 3.8+
- LM Studio running on localhost:1234
- Any model loaded in LM Studio

## üÜò Need Help?

Check the [Quick Start Guide](QUICK_START.md) for common issues like "Failed to create client" or [Setup Instructions](SETUP_INSTRUCTIONS.md) for detailed troubleshooting.

---

**No more model-specific servers!** üéâ One server that adapts to everything. 